```python
import numpy as np

def get_combined_expression_v2(pt: np.ndarray, wkr: np.ndarray, rm: np.ndarray, so: np.ndarray, twk: np.ndarray, ema: np.ndarray) -> np.ndarray:
    # Robust normalization with clipping to avoid extreme ratios
    def normalize(x):
        x_clipped = np.clip(x, 1e-6, None)  # avoid zero or negative to prevent divide issues
        norm_x = x_clipped / (np.max(x_clipped) + 1e-9)
        return norm_x
    
    pt_norm = normalize(pt)
    wkr_norm = normalize(wkr)
    rm_norm = normalize(rm)
    so_norm = normalize(so)
    twk_norm = normalize(twk)
    
    # Tunable smooth nonlinear transforms (softplus) to smooth inputs and limit effect of outliers
    def smooth_transform(x, alpha=5):
        return np.log1p(np.exp(alpha * (x - 0.5))) / alpha
    
    pt_smooth = smooth_transform(pt_norm)
    wkr_smooth = smooth_transform(wkr_norm)
    rm_smooth = smooth_transform(rm_norm)
    so_smooth = smooth_transform(so_norm)
    twk_smooth = smooth_transform(twk_norm)
    
    # Adaptive EMA weighting: higher penalty with larger deviation but capped for stability
    ema_abs = np.abs(ema)
    ema_weight = np.minimum(1.5, 1 + 5 * ema_abs)  # weight from 1 to max 1.5
    
    # Dynamic look-ahead scaling emphasizing succeeding operation relative to total work
    lookahead_raw = so / (twk + 1e-9)
    lookahead_scale = np.tanh(3 * lookahead_raw)  # smooth cap at ~1
    
    # Compose expression:
    # Balanced additive and multiplicative terms combining current, remaining, and look-ahead factors
    base_score = 0.5 * pt_smooth + 0.3 * wkr_smooth + 0.15 * rm_smooth
    lookahead_term = 1 + 1.8 * lookahead_scale
    
    score_raw = base_score * lookahead_term * ema_weight
    
    # Cap extremes to improve stability
    score_capped = np.clip(score_raw, 0, 3)
    
    return score_capped
```
