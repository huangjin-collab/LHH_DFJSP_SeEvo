```python
import numpy as np

def get_combined_expression_v2(
    pt: np.ndarray,
    wkr: np.ndarray,
    rm: np.ndarray,
    so: np.ndarray,
    twk: np.ndarray,
    ema: np.ndarray
) -> np.ndarray:
    eps = 1e-8

    def robust_sigmoid_normalize(x: np.ndarray) -> np.ndarray:
        p_low, p_high = np.percentile(x, [5, 95])
        clipped = np.clip(x, p_low, p_high)
        denom = p_high - p_low if p_high - p_low > eps else 1.0
        normalized = (clipped - p_low) / denom
        # Smooth sigmoid centered at 0.5 with steepness 12
        return 1.0 / (1.0 + np.exp(-12.0 * (normalized - 0.5)))

    # Normalize all key inputs robustly
    pt_n = robust_sigmoid_normalize(pt)
    wkr_n = robust_sigmoid_normalize(wkr)
    rm_n = robust_sigmoid_normalize(rm)
    so_n = robust_sigmoid_normalize(so)
    twk_n = robust_sigmoid_normalize(twk)

    # Compute workload ratio with stability
    workload_ratio = (wkr + eps) / (twk + eps)

    # Adaptive alpha for EMA update: smoothly increasing from 0.15 to 0.85 as workload_ratio grows past 0.38
    alpha = 0.15 + 0.7 / (1.0 + np.exp(-14.0 * (workload_ratio - 0.38)))

    # Calculate realized-to-nominal ratio, clipped for stability and to avoid extreme values
    realized_nominal = pt / (pt + eps)
    realized_nominal_clipped = np.clip(realized_nominal, 0.55, 1.45)

    # Adaptive EMA update proxy reflecting current deviation with dynamic alpha
    ema_adj = alpha * (realized_nominal_clipped - 1.0) + (1 - alpha) * ema
    # Clamp ema_adj to moderate range for stability
    ema_adj = np.clip(ema_adj, -0.55, 0.55)

    # Dynamic center and sharpness for residual ratio bottleneck measure
    residual_ratio_raw = (rm + eps) / (wkr + eps)
    residual_center = 0.52 + 0.12 * np.tanh(6.0 * ema_adj)
    residual_sharpness = 7.5 + 10.5 * np.abs(ema_adj)
    residual_ratio = np.tanh(residual_sharpness * (residual_ratio_raw - residual_center))

    # Bottleneck emphasis sigmoid with dynamic steepness and offset tuned by ema_adj
    sigmoid_steepness = 14.0 + 20.0 * np.abs(ema_adj)
    bottleneck_emphasis = 1.0 / (1.0 + np.exp(-sigmoid_steepness * (residual_ratio_raw - 0.77 - 0.1 * ema_adj)))

    # Look-ahead term enhanced by nonlinear EMA modulation and bottleneck emphasis,
    # combined linear and nonlinear uses of successor time normalized & original scales
    look_ahead = so * (1.0 + np.tanh(4.2 * ema_adj) * bottleneck_emphasis) + 0.55 * so_n

    # Workload factor: smooth log scaling of (pt normalized by twk) modulated by EMA and wkr normalized,
    # highlighting multiplicative synergy of current load and EMA-driven uncertainty
    workload_factor = np.log1p(
        (pt / (twk + eps))
        * (1.0 + 2.0 * np.tanh(3.5 * ema_adj))
        * (1.0 + 0.75 * wkr_n)
    )

    # EMA-weighted, workload-modulated nonlinear interaction term promoting job progress under uncertainty
    ema_workload_interaction = np.tanh(3.8 * ema_adj * wkr_n)

    # Aggregate composite expression balances bottleneck, look-ahead, and current processing time:
    # - the additive workload bottleneck term scaled multiplicatively by the bottleneck emphasis
    # - penalizing lookahead to favor efficient future scheduling load balancing
    # - boosting EMA+workload interaction for priority stabilization under uncertainty
    # - awarding current processing time amplified by bottleneck emphasis to boost critical ops
    combined = (
        workload_factor * (1.0 + residual_ratio * bottleneck_emphasis)
        - 0.65 * look_ahead
        + 0.57 * ema_workload_interaction
        + 0.32 * pt_n * (1.0 + 0.95 * bottleneck_emphasis)
    )

    return combined
```
